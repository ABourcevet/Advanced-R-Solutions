```{r, include=FALSE}
source("common.R")
```

# Measuring performance

    ```{r, include=FALSE}
    library(magrittr)
    ```

## Profiling

1. __[Q]{.Q}__: Profile the following function with `torture = TRUE`. What is surprising? Read the source code of `rm()` to figure out what's going on.

    ```{r}
    f <- function(n = 1e5) {
      x <- rep(1, n)
      rm(x)
    }
    ```

   __[A]{.started}__: Unfortunately, the current version of profvis throws an error

    ```{r, eval = FALSE}
    profvis::profvis(f(), torture = TRUE)
    
    f()
    Error in stri_split_regex(string, pattern, n = n, simplify = simplify,  : 
      unimplemented type 'integer' in 'coerceToInteger'
    ```

<!-- from `?profvis()`: `Toruture` triggers garbage collection after every torture memory allocation call. -->

## Microbenchmarking

1. __[Q]{.Q}__: Instead of using `bench::mark()`, you could use the built-in function `system.time()`. But `system.time()` is much less precise, so you'll need to repeat each operation many times with a loop, and then divide to find the average time of each operation, as in the code below.

    ```{r, eval = FALSE}
    n <- 1e6
    system.time(for (i in 1:n) sqrt(x)) / n
    system.time(for (i in 1:n) x ^ 0.5) / n
    ```
    
   How do the estimates from `system.time()` compare to those from `bench::mark()`? Why are they different?

   __[A]{.started}__: (TODO: Last part of the question: Why are the results different?)
   
   As `bench::mark()` doesn't calculate the mean value, we calculate it from the `time` list-column in the tibble output. 

    ```{r}
    n <- 1e6
    x <- runif(100)
    
    bench_sqrt_power <- bench::mark(
      sqrt(x), 
      x ^ 0.5
    )
    
    bench_sqrt  <- mean(unlist(bench_sqrt_power[1, "time"]))
    bench_power <- mean(unlist(bench_sqrt_power[2, "time"]))
    
    systime_sqrt  <- system.time(for (i in 1:n) sqrt(x)) / n
    systime_power <- system.time(for (i in 1:n) x ^ 0.5) / n
    
    systime_sqrt  <- systime_sqrt[["elapsed"]]
    systime_power <- systime_power[["elapsed"]]

    # Compare the results for sqrt(x)
    systime_sqrt
    bench_sqrt
    abs(systime_sqrt - bench_sqrt)
    
    # Compare the results for x ^ sqrt(0.5)
    systime_power
    bench_power
    abs(systime_power - bench_power)
    ```

   Both approaches get the order of magnitude right. They are different, as `bench::mark()` is more precise. However, on average they give comparable results.

2. __[Q]{.Q}__: Here are two other ways to compute the square root of a vector. Which do you think will be fastest? Which will be slowest? Use microbenchmarking to test your answers.

    ```{r, eval = FALSE}
    x ^ (1 / 2)
    exp(log(x) / 2)
    ```

   __[A]{.solved}__: We'll use the bench package to estimate the relative execution time of these expressions, with the fastest expression standardized to 1.

    ```{r, message=FALSE}
    x <- runif(100)
    
    bench::mark(sqrt(x),          # (1)
                x ^ 0.5,          # (2)
                x ^ (1 / 2),      # (3)
                exp(log(x) / 2),  # (4)
                relative = TRUE) %>% 
      dplyr::select(expression, median) %>% 
      dplyr::arrange(median)
    ```

   As expected, `exp(log(x)/2)` requires the most time to calculate the square root of `x`.
