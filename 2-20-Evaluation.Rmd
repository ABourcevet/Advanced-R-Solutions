```{r, include=FALSE}
source("common.R")
```

# Evaluation

## Prerequisites

```{r, message=FALSE}
library(rlang)
library(purrr)
```

## Evaluation basics

1. __[Q]{.Q}__: Carefully read the documentation for `source()`. What environment does it use by default? What if you supply `local = TRUE`? How do you provide a custom environment?
    
   __[A]{.solved}__: By default, `source()` uses the global environment, but another evaluation environment may also be chosen, by passing it to the `local` argument. To use a local environment set `local = TRUE`.
    
    ```{r}
    # Create temporary, sourcable R script
    tmp_file <- tempfile()
    writeLines("print(x)", tmp_file)
    
    # Set x globally
    x <- "global environment"
    env2 <- rlang::env(x = "specified envirionment")
    
    locate_evaluation <- function(file, local){
      x <- "local environment"
      source(file, local = local)
    }
    
    # Where will source() be evaluated?
    locate_evaluation(tmp_file, local = FALSE)  # default
    locate_evaluation(tmp_file, local = env2)
    locate_evaluation(tmp_file, local = TRUE)
    ```

2. __[Q]{.Q}__: Predict the results of the following lines of code:

    ```{r, eval = FALSE}
    eval(expr(eval(expr(eval(expr(2 + 2))))))        # (1)
    eval(eval(expr(eval(expr(eval(expr(2 + 2)))))))  # (2)
    expr(eval(expr(eval(expr(eval(expr(2 + 2)))))))  # (3)
    ```

   __[A]{.solved}__: To quote Hadley analogously from the first edition of Advanced R: "`expr()` and `eval()` are opposites. ... each `eval()` peels off one layer of `expr()`'s". I.e. `eval(expr(x))` evaluates to  `x`. Therefore, (1) evaluates to $2 + 2 = 4$. Adding another `eval()` doesn't have impact here. So, also (2) evaluates to 4. However, when wrapping (1) into `expr()` the whole expression gets quoted. 

    ```{r}
    eval(expr(eval(expr(eval(expr(2 + 2))))))        # (1)
    eval(eval(expr(eval(expr(eval(expr(2 + 2)))))))  # (2)
    expr(eval(expr(eval(expr(eval(expr(2 + 2)))))))  # (3)
    ```

3. __[Q]{.Q}__: Fill in the function bodies below to re-implement `get()` using `sym()` and `eval()`, and`assign()` using `sym()`, `expr()`, and `eval()`. Don't worry about the multiple ways of choosing an environment that `get()` and `assign()` support; assume that the user supplies it explicitly

    ```{r}
    # name is a string
    get2 <- function(name, env) {}
    assign2 <- function(name, value, env) {}
    ```

   __[A]{.solved}__: The reimplemantion of these two functions using tidy evaluation is based on building an expression, which is then evaluated.

    ```{r}
    get2 <- function(name, env = caller_env()) {
      name_sym <- sym(name)
      eval(name_sym, env)
    }
    
    x <- 1
    get2("x")
    ```

   The implementation could be even more concise, if the user would provide an expression instead of a string:

    ```{r}
    get3 <- function(name, env = caller_env()){
      eval(name, env)
    }
    
    get3(x)
    ```

   To build the correct expression for the value assignment, we unquote using `!!`.

    ```{r}
    assign2 <- function(name, value, env = caller_env()) {
      name_sym <- sym(name)
      assign_expr <- expr(!!name_sym <- !!value)
      eval(assign_expr, env)
    }
    
    assign2("x", 4)
    x
    ```
    
4. __[Q]{.Q}__: Modify `source2()` so it returns the result of _every_ expression, not just the last one. Can you eliminate the for loop?

   __[A]{.solved}__: In order to make the modifications more apparent, we just keep the code from the former `source2()`-version as a comment.
   
    ```{r}
    source2 <- function(path, env = caller_env()) {
      file <- paste(readLines(path, warn = FALSE), collapse = "\n")
      exprs <- parse_exprs(file)
      
      # res <- NULL
      # for (i in seq_along(exprs)) {
      #   res <- eval(exprs[[i]], env)
      # }
      
      res <- vector(mode = "list", length = length(exprs))      
      for (i in seq_along(exprs)) {
        res[[i]] <- eval(exprs[[i]], env)
      }
      
      invisible(res)
    }
    ```
    
   Let's create a file and test `source2()`. Keep in mind that `<-` returns invisibly.
   
    ```{r}
    tmp_file <- tempfile()
    writeLines(
      "x <- 1
      x
      y <- 2
      y  # some comment",
      tmp_file
    )

    (source2(tmp_file))
    ```
    
   To eliminate the for loop, we can simply use `map()`:
   
    ```{r}
    source2 <- function(path, env = caller_env()) {
      file <- paste(readLines(path, warn = FALSE), collapse = "\n")
      exprs <- parse_exprs(file)
      
      res <- map(exprs, eval, env)
      
      invisible(res)
    }
    
    # Test:
    (source2(tmp_file))
    ```

5. __[Q]{.Q}__: We can make `base::local()` slightly easier to understand by spreading it over multiple lines:

    ```{r}
    local3 <- function(expr, envir = new.env()) {
      call <- substitute(eval(quote(expr), envir))
      eval(call, envir = parent.frame())
    }
    ```
    
   Explain how `local()` works in words. (Hint: you might want to `print(call)` to help understand what `substitute()` is doing, and read the documentation to remind yourself what environment `new.env()` will inherit from.)

   __[A]{.solved}__:

    ```{r}
    local3 <- function(expr, envir = new.env()) {
      call <- substitute(eval(quote(expr), envir))
      print(call)
      eval(call, envir = parent.frame())
    }
    
    foo <- local3({
      x <- 10
      x * 2
    })
    
    foo
    ```

   `substitute()` only replaces the expr with the input and the environment (for the call to eval) by the relate

    ```{r}
    # how does substitute work?
    ```

   - substitute opperates in function execution environment, it replaces the variables bound in this environments by their expression (expr becomes the input, and envir, becomes the environment passed to `local3` (new.env() by default))

   <!-- this needs a better description based on the AST, @Malte -->
    
    ```{r}
    # this is, what is happening afterwards
    eval(eval(quote({x <- 10; x * 2}), new.env()), parent.frame())
    
    eval(quote({x <- 10; x * 2}), new.env())  # this is evaluated locally
    
    eval(20, parent.frame())  # makes it available in the caller environment
    ```
    
## Quosures

1. __[Q]{.Q}__: Predict what evaluating each of the following quosures will return if evaluated.

    ```{r}
    library(rlang)
    
    q1 <- new_quosure(expr(x), env(x = 1))
    q1
    
    q2 <- new_quosure(expr(x + !!q1), env(x = 10))
    q2
    
    q3 <- new_quosure(expr(x + !!q2), env(x = 100))
    q3
    ```
    
   __[A]{.solved}__: Each quosure will be evaluated in its own environment. This leads us to:
    
    ```{r}
    eval_tidy(q1)
    eval_tidy(q2)
    eval_tidy(q3)
    ```

2. __[Q]{.Q}__: Write an `enenv()` function that captures the environment associated with an argument. (Hint: this should only require two function calls.)

   __[A]{.solved}__: A quosure captures both the expression and the environment. From a quosure, we can access the environment with the help of `get_env()`.

    ```{r}
    enenv <- function(x){
      q <- enquo(x)
      get_env(q) 
    }
    
    # Test
    capture_env <- function(x){
      enenv(x)
    }
    
    enenv(x)
    capture_env(x)  # functions execution environment is captured
    ```

## Data masks

1. __[Q]{.Q}__: Why did I use a for loop in `transform2()` instead of `map()`? Consider `transform2(df, x = x * 2, x = x * 2)`.
   
   __[A]{.solved}__: Via the for loop approach the processing steps regarding `.data` are applied iteratively. This includes updating `.data` and reusing the same variable names, which enables to apply transformations sequentially so that transformation can refer to columns that were just created.

2. __[Q]{.Q}__: Here's an alternative implementation of `subset2()`:

    ```{r, results = FALSE}
    subset3 <- function(data, rows) {
      rows <- enquo(rows)
      eval_tidy(expr(data[!!rows, , drop = FALSE]), data = data)
    }

    df <- data.frame(x = 1:3)
    subset3(df, x == 1)
    ```

   Compare and contrast `subset3()` to `subset2()`. What are its advantages and disadvantages?

   __[A]{.solved}__: Let's take a closer look at subset2() first:
   
    ```{r}
    subset2 <- function(data, rows) {
      rows <- enquo(rows)
      rows_val <- eval_tidy(rows, data)
      stopifnot(is.logical(rows_val))
      
      data[rows_val, , drop = FALSE]
    }
    ```

   We see, that there is an additional logical check, which is missing from `subset3()`. The here the logical condition `rows` is evaluated in the context of `data`, which results in a logical vector used for subsetting. Afterwards only `[` needs to be used to return the subset.

    ```{r}
    # subset2() evaluation
    (rows_val <- eval_tidy(quo(x == 1), df))
    df[rows_val, , drop = FALSE]
    ```

   With `subset3()` both of these steps occur in a single line. This means, that the subsetting is also evaluated in the context of the data mask.

    ```{r}
    # subset3() evaluation
    eval_tidy(expr(df[x == 1, ,drop = FALSE]), df)
    ```

   This is shorter, but also less readable, because the evaluation and the subsetting take place in the same expression. It may also introduce unwanted errors, if the data mask should contain an element named `data`, because the object from the data mask takes precedence over argument of the function.

    ```{r, error=TRUE}
    df <- data.frame(x = 1:3, data = 1)
    subset2(df, x == 1)
    subset3(df, x == 1)
    ```

<!-- is there an advantage of `subset3()`, that I am missing? -->

3. __[Q]{.Q}__: The following function implements the basics of `dplyr::arrange()`. Annotate each line with a comment explaining what it does. Can you explain why `!!.na.last` is strictly correct, but omitting the `!!` is unlikely to cause problems?

    ```{r}
    arrange2 <- function(.df, ..., .na.last = TRUE) {
      args <- enquos(...)

      order_call <- expr(order(!!!args, na.last = !!.na.last))

      ord <- eval_tidy(order_call, .df)
      stopifnot(length(ord) == nrow(.df))

      .df[ord, , drop = FALSE]
    }
    ```

   __[A]{.solved}__: This function builds an expression, which contains the specified `order()`-call. The `!!!`-operator is used, which allows multiple arguments to be included (to break ties). Once the correct roworder is determined, numeric subsetting is used to return the rearranged data frame.

    ```{r}
    arrange2 <- function(.df, ..., .na.last = TRUE) {
      args <- enquos(...)  # capture arguments, which determine order
      
      order_call <- expr(order(!!!args, na.last = !!.na.last))
      # `!!!`: unquote-splice arguments into order()
      # `!!.na.last`: pass option for treatment of NAs to order()
      # return expression-object

      ord <- eval_tidy(order_call, .df)    # evaluate order_call within .df
      stopifnot(length(ord) == nrow(.df))  # ensure that no rows are dropped

      .df[ord, , drop = FALSE]  # reorder rows by numeric subsetting
    }
    ```

   By using `!!.na.last` the `.na.last`-argument is unquoted, when the `order()`-call is built. That way, the `na.last`-argeument is already correctly specified (typically `TRUE`, `FALSE` or `NA`).

   Without the unquoting, the expression would read `na.last = .na.last`. The value for `.na.last` would still have to be looked up and found. Because these computations take place inside of the functions execution environment (which contains `.na.last`), this is unlikely to cause problems.

    ```{r}
    # the effect of unquoting .na.last
    .na.last <- FALSE
    expr(order(..., na.last = !!.na.last))
    expr(order(..., na.last = .na.last))
    ```

   PS: Putting breakpoints (`browser()`) inside these functions was really helpful to figure out, what's going on inside of them.

## Using tidy evaluation

1. __[Q]{.Q}__:  I've included an alternative implementation of `threshold_var()` below. What makes it different to the approach I used above? What makes it harder?

    ```{r}
    threshold_var2 <- function(df, var, val) {
      var <- ensym(var)

      subset2(df, `$`(.data, !!var) >= !!val)
    }
    ```

   __[A]{.started}__: Lets compare this approach to the original implementation:

    ```{r}
    threshold_var <- function(df, var, val) {
      var <- as_string(ensym(var))
      subset2(df, .data[[var]] >= !!val)
    }
    ```

   We can see, that the symbol in no longer coerced to a string in `threshold_var2()`. Therefore `$` instead of `[[` is used for subsetting. Initially we suspected partial matching to work with `$`, but this seems to avoided, when the expression is tidily evaluated.

   The prefix call to `$()` is less common than infix-subsetting using `[[`, but ultimately both functions seem to behave the same.

    ```{r}
    df <- data.frame(x = 1:10)
    threshold_var(df, x, 8)
    threshold_var2(df, x, 8)
    ```

<!-- I am probably missing sth here. What makes the second approach **harder**? -->

## Base evaluation

1. __[Q]{.Q}__: Why does this function fail?

    ```{r, error = TRUE}
    lm3a <- function(formula, data) {
      formula <- enexpr(formula)
      
      lm_call <- expr(lm(!!formula, data = data))
      eval(lm_call, caller_env())
    }
    lm3a(mpg ~ disp, mtcars)$call
    ```

   __[A]{.solved}__: In this function, `lm_call` is evaluated in the caller environment, which happens to be the global environment. In this environment, the name `data` is bound to `utils::data`. To fix the error, we can either set the evaluation environment to the functions execution environment or unquote the data argument when building the call to `lm()`.
    
    ```{r, error = TRUE}
    # change evaluation environment
    lm3b <- function(formula, data) {
      formula <- enexpr(formula)
      
      lm_call <- expr(lm(!!formula, data = data))
      eval(lm_call, current_env())
    }
    
    lm3b(mpg ~ disp, mtcars)$call
    lm3b(mpg ~ disp, data)$call  #reproduces original error
    ```

   When we want to unquote an argument within a function, we first need to capture the user-input (by `enenxpr()`).

    ```{r, error = TRUE}
    # unquoting data-argument
    lm3c <- function(formula, data) {
      formula <- enexpr(formula)
      data_quo <- enexpr(data)

      lm_call <- expr(lm(!!formula, data = !!data_quo))
      eval(lm_call, caller_env())
    }
    lm3c(mpg ~ disp, mtcars)$call
    ```

2. __[Q]{.Q}__: When model building, typically the response and data are relatively constant while you rapidly experiment with different predictors. Write a small wrapper that allows you to reduce duplication in the code below.

    ```{r, eval = FALSE}
    lm(mpg ~ disp, data = mtcars)
    lm(mpg ~ I(1 / disp), data = mtcars)
    lm(mpg ~ disp * cyl, data = mtcars)
    ```

   __[A]{.solved}__: In our wrapper `lm_wrap()`, we provide `mpg` and `mtcars` as default response and data. This seems to give us a good mix of usability and flexibility.

    ```{r}
    lm_wrap <- function(pred, resp = mpg, data = mtcars, env = caller_env()) {
      pred <- enexpr(pred)
      resp <- enexpr(resp)
      data <- enexpr(data)
      
      formula <- expr(!!resp ~ !!pred)
      lm_call <- expr(lm(!!formula, data = !!data))
      eval(lm_call, envir = env)
    }
    
    # Test if the output looks ok
    lm_wrap(I(1 / disp) + disp * cyl)
    
    # Test if the result is identical to calling lm() directly
    identical(
      lm_wrap(I(1 / disp) + disp * cyl),
      lm(mpg ~ I(1 / disp) + disp * cyl, data = mtcars)
    )
    ```

3. __[Q]{.Q}__: Another way to write `resample_lm()` would be to include the resample expression `(data[sample(nrow(data), replace = TRUE), , drop = FALSE])` in the data argument. Implement that approach. What are the advantages? What are the disadvantages?

   __[A]{.solved}__: We can take advantage of the lazy evaluation of function arguments, by moving the resampling step into the argument definition. The uses passes the data to the function, but only a permutation of this data (`rsampled_data`) will be used.

    ```{r}
    resample_lm0 <- function(
      formula, data,
      resample_data = data[sample(nrow(data), replace = TRUE), , drop = FALSE],
      env = current_env()
    ) {
      formula <- enexpr(formula)
      
      lm_call <- expr(lm(!!formula, data = resample_data))
      expr_print(lm_call)
      eval(lm_call, env)
    }
    
    df <- data.frame(x = 1:10, y = 5 + 3 * (1:10) + round(rnorm(10), 2))
    (resamp_lm1 <- resample_lm0(y ~ x, data = df))
    resamp_lm1$call
    ```

   With this approach the evaluation needs to take place within the functions environments, because the resampled dataset (defined as a default argument) will only be available in the function environment.

   Overall, putting an essential part of the preprocessing outside of the functions body is not common practice in R. Compared to the unquoting-implementation (`resample_lm1()`), this approach captures the model-call in a more meaningful way.

<!-- would be nice to list a few more advantages and disadvantages -->

## Old exercises

1. __[Q]{.Q}__: Run this code in your head and predict what it will print. Confirm or refute your prediction by running the code in R.

    ```{r, results = FALSE}
    f <- function(...) {
      x <- "f"
      g(f = x, ...)
    }
    g <- function(...) {
      x <- "g"
      h(g = x, ...)
    }
    h <- function(...) {
      enquos(...)
    }
    x <- "top"
    
    out <- f(top = x)
    out
    purrr::map_chr(out, eval_tidy)
    ```

1. __[Q]{.Q}__: What happens if you use `expr()` instead of `enexpr()` inside of `subset2()`?


1. __[Q]{.Q}__: Improve `subset2()` to make it more like real `base::subset()`:
    
   * Drop rows where `subset` evaluates to `NA`
   * Give a clear error message if `subset` doesn't yield a logical vector
   * What happens if `subset` yields a vector that's not the same as the number of rows in `data`? What do you think should happen?
      
2. __[Q]{.Q}__: The third argument in `base::subset()` allows you to select variables. It treats variable names as if they were positions. This allows you to do things like `subset(mtcars, , -cyl)` to drop the cylinder variable, or `subset(mtcars, , disp:drat)` to select all the variables between `disp` and `drat`. How does this work? I've made this easier to understand by extracting it out into its own function that uses tidy evaluation.

    ```{r, eval = FALSE}
    select <- function(df, vars) {
      vars <- enexpr(vars)
      var_pos <- set_names(as.list(seq_along(df)), names(df))
      
      cols <- eval_tidy(vars, var_pos)
      df[, cols, drop = FALSE]
    }
    select(mtcars, -cyl)
    ```
    
3. __[Q]{.Q}__: Here's an alternative implementation of `arrange()`:

    ```{r}
    invoke <- function(fun, ...) do.call(fun, dots_list(...))
    arrange3 <- function(.data, ..., .na.last = TRUE) {
      args <- enquos(...)
      
      ords <- purrr::map(args, eval_tidy, data = .data)
      ord <- invoke(order, !!!ords, na.last = .na.last)
      
      .data[ord, , drop = FALSE]
    }
    ```
    
   Describe the primary difference in approach compared to the function defined in the text. 
    
   One advantage of this approach is that you could check each element of `...` to make sure that input is correct. What property should each element of `ords` have?

4. __[Q]{.Q}__: Here's an alternative implementation of `subset2()`:

    ```{r}
    subset3 <- function(data, rows) {
      eval_tidy(quo(data[!!enquo(rows), , drop = FALSE]), data = data)
    }
    ```
    
   Use intermediate variables to make the function easier to understand, then
   explain how this approach differs to the approach in the text.

5. __[Q]{.Q}__: Implement a form of `arrange()` where you can request a variable to sorted in descending order using named arguments:
    
    ```{r, eval = FALSE}
    arrange(mtcars, cyl, desc = mpg, vs)
    ```
    
   (Hint:  The `descreasing` argument to `order()` will not help you. Instead, look at the definition of `dplyr::desc()`, and read the help for `xtfrm()`.)

6. __[Q]{.Q}__: Why do you not need to worry about ambiguous argument names with `...` in
    `arrange()`? Why is it a good idea to use the `.` prefix anyway?

7. __[Q]{.Q}__: What does `transform()` do? Read the documentation. How does it work?
   Read the source code for `transform.data.frame()`. What does `substitute(list(...))` do?
   
8. __[Q]{.Q}__: Use tidy evaluation to implement your own version of `transform()`.
   Extend it so that a calculation can refer to variables created by transform, i.e. make this work:
    
    ```{r, error = TRUE}
    df <- data.frame(x = 1:3)
    transform(df, x1 = x + 1, x2 = x1 + 1)
    ```

9. __[Q]{.Q}__: What does `with()` do? How does it work? Read the source code for `with.default()`. What does `within()` do? How does it work? Read the source code for `within.data.frame()`. Why is the code so much more
    complex than `with()`?
   
10. __[Q]{.Q}__: Implement a version of `within.data.frame()` that uses tidy evaluation.
    Read the documentation and make sure that you understand what `within()` does, then read the source code.
    
<!-- ## Wrapping quoting functions -->

1. __[Q]{.Q}__: When model building, typically the response and data are relatively constant while you rapidly experiment with different predictors. Write a small wrapper that allows you to reduce duplication in this situation.
    
    ```{r, eval = FALSE}
    pred_mpg <- function(resp, ...) {
      
    }
    pred_mpg(~ disp)
    pred_mpg(~ I(1 / disp))
    pred_mpg(~ disp * cyl)
    ```
    
2. __[Q]{.Q}__: Another way to way to write `boot_lm()` would be to include the boostrapping expression (`data[sample(nrow(data), replace = TRUE), , drop = FALSE]`) in the data argument. Implement that approach. What are the advantages? What are the disadvantages?

3. __[Q]{.Q}__: To make these functions somewhat more robust, instead of always using the `caller_env()` we could capture a quosure, and then use its environment. However, if there are multiple arguments, they might be associated with different environments. Write a function that takes a list of quosures, and returns the common environment, if they have one, or otherwise throws an error.

4. __[Q]{.Q}__: Write a function that takes a data frame and a list of formulas, fitting a linear model with each formula, generating a useful model call.

5. __[Q]{.Q}__: Create a formula generation function that allows you to optionally supply a transformation function (e.g. `log()`) to the response or the predictors.

## Deprecated evaluation basics

1. __[Q]{.Q}__: The code generated by `source2()` lacks source references. Read the source code for `sys.source()` and the help for `srcfilecopy()`, then modify `source2()` to preserve source references. You can test your code by sourcing a function that contains a comment. If successful, when you look at the function, you'll see the comment and not just the source code.

   __[A]{.started}__:

    ```{r, error=TRUE}
    tmp_file <- tempfile()
    writeLines('x <- 1
    test_function <- function() {
    "source me!"  # testcomment
    }', tmp_file)
    
    file <- tmp_file
    
    source2 <- function(file, env = caller_env()){
      lines <- readLines(file)
      srcfile <- srcfilecopy(file, lines)
      
      parse(text = lines, srcfile = srcfile, keep.source = TRUE) %>% 
        map(eval_tidy, env = env) 
    }
    
    source2(tmp_file)
    test_function
    ```

   - the comment is still missing
